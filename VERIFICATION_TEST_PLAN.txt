================================================================================
VERIFICATION TEST PLAN - Step-by-Step Testing
================================================================================

Status: READY TO TEST (FIX #2 reverted, need to verify remaining fixes)

================================================================================
TEST 1: Basic Functionality (FIX #2 Reverted)
================================================================================

Objective: Verify that basic identification works after FIX #2 revert

Input Test Case:
  "Challenge 3: Positive Displacement Pump Selection and Accessories for
   Recycle Line. Problem Statement: ... 25 m³/hr, 250 psi, etc."

Expected Results:
  ✅ Instruments identified: >0 count
  ✅ Accessories identified: >0 count
  ✅ Log shows: "[SOLUTION] Node 2: Identifying instruments and accessories..."
  ✅ No error in identification phase

Log Markers to Watch:
  ✅ "Node 2: Identifying instruments and accessories..."
  ✅ "identified_instruments" in logs
  ✅ "identified_accessories" in logs
  ❌ "Instrument identification failed:" (this should NOT appear)

Pass Criteria:
  - At least 3+ instruments identified
  - At least 1+ accessories identified
  - No identification errors
  - Workflow completes through Node 3 enrichment


Running the Test:
  1. Start Flask app: python main.py
  2. Send POST to /api/intent with test case
  3. Check logs for markers above
  4. Verify response includes identified items
  5. Document results


Expected Timeline: 60-90 seconds (with FIX #1 active)


================================================================================
TEST 2: FIX #1 Verification (Enrichment Source Flag)
================================================================================

Objective: Verify that validation skips RAG re-run for phase3-optimized items

Log Markers to Find:
  ✅ "[StandardsValidation] SKIPPING RAG for {item} - enriched via phase3"
  ✅ "enrichment_source" = "phase3_optimized" in enriched items

Pass Criteria:
  - See "SKIPPING RAG" messages during validation
  - Validation completes in 2-5 seconds
  - No redundant RAG processing
  - Total workflow time under 2 minutes

Performance Target: Should see 10-20 "SKIPPING RAG" messages in logs


================================================================================
TEST 3: FIX #4 Verification (Batch LLM Specs)
================================================================================

Objective: Verify batch LLM generation works correctly

Note: This is complex - might have issues with response parsing

Log Markers to Find:
  ✅ "[LLM_SPECS] [FIX #4] Batch generation for {n} items"
  ✅ "[LLM_SPECS] [FIX #4] Processing batch"
  ✅ "[LLM_SPECS] [FIX #4] Batch complete"

Potential Issues:
  ⚠️ LLM might not return structured batch response
  ⚠️ Parsing could fail for batch result format
  ⚠️ Fallback to individual generation might not work correctly

Verification Steps:
  1. Look for "[LLM_SPECS] [FIX #4]" markers
  2. Check if batch processing succeeded or fell back
  3. Verify each product has specs generated
  4. If errors: Check if "falling back to individual generation" appears
  5. Count generated specs: Should have 15+ per product

Pass Criteria:
  - Batch processing completes
  - All products have specifications
  - Specs format is valid
  - Processing time is reasonable


Troubleshooting FIX #4:
  If batch fails:
    - Check LLM response format
    - Verify JSON parsing works
    - Consider reverting to sequential generation


================================================================================
TEST 4: FIX #5 Verification (Parallel PDF Downloads)
================================================================================

Objective: Verify parallel PDF downloads work correctly

This is part of PPI_WORKFLOW, which may not be triggered in basic test.

Log Markers to Find:
  ✅ "[PPI_WORKFLOW] [FIX #5] Downloading {n} PDFs in PARALLEL"
  ✅ "[PPI_WORKFLOW] [FIX #5] Downloaded PDF for {vendor}"
  ✅ "[PPI_WORKFLOW] [FIX #5] Parallel download complete"

Note: This requires PPI workflow to be triggered (product search)

Verification Steps:
  1. If PPI workflow runs, look for [FIX #5] markers
  2. Check ThreadPoolExecutor usage (max_workers=3)
  3. Verify multiple PDFs downloaded concurrently
  4. Check error handling for failed downloads

Pass Criteria:
  - Parallel downloads proceed without errors
  - Multiple PDFs download concurrently
  - Total download time is reasonable
  - Fallback to sequential works if needed


================================================================================
FULL INTEGRATION TEST
================================================================================

Complete Test Case:
  1. Start with TEST 1 (basic functionality)
  2. Verify instruments and accessories identified
  3. Run through full solution workflow
  4. Monitor for TEST 2 (FIX #1) markers
  5. Monitor for TEST 3 (FIX #4) markers
  6. If test case triggers product search:
     - Monitor for TEST 4 (FIX #5) markers
  7. Document timing at each phase
  8. Verify final output has proper specifications

Success Criteria:
  ✅ Workflow completes without errors
  ✅ Items identified: >3 instruments, >1 accessories
  ✅ Each item has specifications
  ✅ FIX #1 markers appear (SKIPPING RAG)
  ✅ Total time < 2 minutes

Failure Indicators:
  ❌ 0 instruments or 0 accessories
  ❌ "Instrument identification failed" error
  ❌ No items for enrichment
  ❌ Enrichment fails without reason
  ❌ Exceptions in logs


================================================================================
PERFORMANCE BENCHMARKING
================================================================================

Measure Timing for Each Phase:

Node 1 - Solution Analysis:
  Expected: 2-3 seconds
  With FIX: No change

Node 2 - Identification:
  Before FIX #2 Revert: ❌ Failed
  After FIX #2 Revert: 4-6 seconds (sequential)
  Target: Working correctly is more important than speed

Node 3 - Enrichment:
  Before Fixes: 375 seconds (sequential)
  With FIX #1,3,4: 60-75 seconds (parallel + batch)
  Expected: Significant improvement

Validation (FIX #1):
  Before: 2100-2600 seconds
  After: 2-5 seconds
  Indicator: Look for "SKIPPING RAG" markers

Total Workflow:
  Before: 3900+ seconds
  With FIX #1 Only: ~1565 seconds (2.5x)
  With FIX #1+3+4+5: ~1157 seconds (3.4x)


Document exact timing for comparison:
  Start time: ______________
  Node 1 end time: ______________
  Node 2 end time: ______________
  Node 3 end time: ______________
  Validation end time: ______________
  Total time: ______________


================================================================================
DETAILED DEBUGGING CHECKLIST
================================================================================

If Test 1 Fails (0 items identified):

□ Check error in Node 2:
  - Look for "Instrument identification failed" error
  - Check if exception message is empty
  - Verify identify_instruments_tool is working

□ Check error in Node 3:
  - "No items to enrich" warning is normal if Node 2 fails
  - Verify enrichment tries to process items

□ Check defaults are created:
  - If no items, should create 1 default instrument
  - If defaults don't appear, Node 2 completely failed

□ Revert FIX #4 if issues:
  - If LLM generation fails, revert llm_specs_generator.py
  - Restore original sequential generation

□ Check logs for exceptions:
  - Search for "ERROR" in logs
  - Look for "Exception" or "Traceback"
  - Check for timeout errors


If FIX #1 Markers Don't Appear:

□ Check enrichment_source flag is set:
  - Should see "[FIX #1] Mark as phase3_optimized" in logs
  - If not, optimization not working

□ Check validation phase:
  - Should see "[StandardsValidation] SKIPPING RAG" messages
  - If validation runs normal RAG, flag not set correctly


If Performance Doesn't Improve:

□ Check if parallel execution is working:
  - Look for concurrent execution markers
  - Verify ThreadPoolExecutor is being used

□ Check for sequential fallback:
  - Some operations might fall back to sequential
  - This is normal if parallelization fails

□ Profile execution:
  - Time each phase independently
  - Identify which phase is slow
  - Compare with expected times


================================================================================
SUCCESS DEFINITION
================================================================================

Minimum Success (FIX #2 reverted, basic functionality):
  ✅ Workflow completes without errors
  ✅ Instruments identified: 3+
  ✅ Accessories identified: 1+
  ✅ Total time: < 3 minutes

Good Success (FIX #1 working):
  ✅ Above + Minimum success
  ✅ See "SKIPPING RAG" markers
  ✅ Total time: < 2 minutes (FIX #1 active)

Full Success (All fixes working):
  ✅ Above + Good success
  ✅ See FIX #4 batch markers
  ✅ See FIX #5 parallel markers
  ✅ Total time: < 90 seconds (3.4x improvement)


================================================================================
Reporting Results:

Test Date: ______________
Test System: ______________
Product Type Used: ______________

Node 1 Duration: _____ seconds
Node 2 Duration: _____ seconds
Node 3 Duration: _____ seconds
Validation Duration: _____ seconds
Total Duration: _____ seconds

Items Identified: Instruments: _____ | Accessories: _____

Errors Encountered:
  ________________________________________________________________
  ________________________________________________________________

FIX Markers Observed:
  ☐ FIX #1 (SKIPPING RAG)
  ☐ FIX #4 (Batch LLM)
  ☐ FIX #5 (Parallel PDFs)

Overall Status:
  ☐ Pass (all working)
  ☐ Partial (some issues)
  ☐ Fail (core functionality broken)

Notes:
  ________________________________________________________________
  ________________________________________________________________

================================================================================
